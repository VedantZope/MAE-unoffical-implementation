dataset: cifar100
data_root: data

# MAE paper setting: 224px + patch16
img_size: 224
patch_size: 16

# ViT-Tiny (compact)
embed_dim: 192
encoder_depth: 12
encoder_heads: 3
encoder_mlp_ratio: 4.0
dropout: 0.0

# Decoder width ~ 1/2 encoder width (efficiency)
decoder_dim: 96
decoder_depth: 2
decoder_heads: 3
decoder_mlp_ratio: 4.0

# Ablation: mask ratio
mask_ratio: 0.5

# Optim / schedule (warmup + cosine like MAE paper, but compact epochs)
batch_size: 1024
epochs: 100
# MAE paper uses lr = 1.5e-4 * (batch / 256)
lr: 0.0006
min_lr: 0.0
warmup_epochs: 10
weight_decay: 0.05

amp: true
grad_accum_steps: 1

num_workers: 12
log_interval: 10
output_dir: experiments/mae_pretrained
seed: 42
norm_pix_loss: true

# Tracking
use_wandb: true
wandb_project: mae-compact
wandb_run_name: mae_vit_tiny_cifar100_m50_d2
wandb_tags: ["pretrain", "vit_tiny", "cifar100", "mask50", "dec2"]
wandb_mode: online
